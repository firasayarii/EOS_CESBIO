{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Layer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler , OneHotEncoder\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tg_scat</th>\n",
       "      <th>Tg_abs</th>\n",
       "      <th>Ta_abs</th>\n",
       "      <th>SSA</th>\n",
       "      <th>GOD</th>\n",
       "      <th>AOD</th>\n",
       "      <th>AODS</th>\n",
       "      <th>SZA</th>\n",
       "      <th>Z</th>\n",
       "      <th>R_scence</th>\n",
       "      <th>g1</th>\n",
       "      <th>Cos(SZA)</th>\n",
       "      <th>mu_g</th>\n",
       "      <th>mu_a</th>\n",
       "      <th>muprime_g</th>\n",
       "      <th>muprime_a</th>\n",
       "      <th>mprime_g</th>\n",
       "      <th>mprime_a</th>\n",
       "      <th>BOA_RT</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.984234</td>\n",
       "      <td>0.967931</td>\n",
       "      <td>0.849827</td>\n",
       "      <td>0.595673</td>\n",
       "      <td>0.015892</td>\n",
       "      <td>0.402452</td>\n",
       "      <td>0.239730</td>\n",
       "      <td>81.357114</td>\n",
       "      <td>1137.064781</td>\n",
       "      <td>0.370253</td>\n",
       "      <td>0.946187</td>\n",
       "      <td>0.150275</td>\n",
       "      <td>708.015229</td>\n",
       "      <td>3186.068532</td>\n",
       "      <td>0.154730</td>\n",
       "      <td>0.151289</td>\n",
       "      <td>5.695816</td>\n",
       "      <td>3.743539</td>\n",
       "      <td>429.332315</td>\n",
       "      <td>0.133511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.808703</td>\n",
       "      <td>0.502863</td>\n",
       "      <td>0.971936</td>\n",
       "      <td>0.754977</td>\n",
       "      <td>0.212324</td>\n",
       "      <td>0.116173</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>69.669734</td>\n",
       "      <td>2695.217813</td>\n",
       "      <td>0.364243</td>\n",
       "      <td>0.910936</td>\n",
       "      <td>0.347431</td>\n",
       "      <td>708.188358</td>\n",
       "      <td>3186.847609</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.347828</td>\n",
       "      <td>2.122562</td>\n",
       "      <td>0.747097</td>\n",
       "      <td>194.210750</td>\n",
       "      <td>0.363279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266592</td>\n",
       "      <td>0.973465</td>\n",
       "      <td>0.845395</td>\n",
       "      <td>0.580608</td>\n",
       "      <td>1.322036</td>\n",
       "      <td>0.400463</td>\n",
       "      <td>0.232512</td>\n",
       "      <td>17.550390</td>\n",
       "      <td>1081.897319</td>\n",
       "      <td>0.672173</td>\n",
       "      <td>0.896924</td>\n",
       "      <td>0.953452</td>\n",
       "      <td>708.009100</td>\n",
       "      <td>3186.040949</td>\n",
       "      <td>0.953519</td>\n",
       "      <td>0.953467</td>\n",
       "      <td>0.929959</td>\n",
       "      <td>0.610609</td>\n",
       "      <td>648.404343</td>\n",
       "      <td>0.280041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830782</td>\n",
       "      <td>0.963485</td>\n",
       "      <td>0.971736</td>\n",
       "      <td>0.270474</td>\n",
       "      <td>0.185388</td>\n",
       "      <td>0.039302</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>44.256621</td>\n",
       "      <td>81.149965</td>\n",
       "      <td>0.775990</td>\n",
       "      <td>0.869940</td>\n",
       "      <td>0.716221</td>\n",
       "      <td>707.897906</td>\n",
       "      <td>3185.540575</td>\n",
       "      <td>0.716701</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>1.382759</td>\n",
       "      <td>1.340499</td>\n",
       "      <td>885.138727</td>\n",
       "      <td>0.125099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600291</td>\n",
       "      <td>0.839312</td>\n",
       "      <td>0.797427</td>\n",
       "      <td>0.652968</td>\n",
       "      <td>0.510340</td>\n",
       "      <td>0.652287</td>\n",
       "      <td>0.425923</td>\n",
       "      <td>24.480144</td>\n",
       "      <td>932.892398</td>\n",
       "      <td>0.777209</td>\n",
       "      <td>0.878946</td>\n",
       "      <td>0.910105</td>\n",
       "      <td>707.992544</td>\n",
       "      <td>3185.966446</td>\n",
       "      <td>0.910238</td>\n",
       "      <td>0.910135</td>\n",
       "      <td>0.990440</td>\n",
       "      <td>0.689159</td>\n",
       "      <td>602.697524</td>\n",
       "      <td>0.320636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362498</th>\n",
       "      <td>0.765135</td>\n",
       "      <td>0.641704</td>\n",
       "      <td>0.963197</td>\n",
       "      <td>0.825442</td>\n",
       "      <td>0.267702</td>\n",
       "      <td>0.214810</td>\n",
       "      <td>0.177313</td>\n",
       "      <td>22.962506</td>\n",
       "      <td>183.428535</td>\n",
       "      <td>0.740243</td>\n",
       "      <td>0.668902</td>\n",
       "      <td>0.920760</td>\n",
       "      <td>707.909270</td>\n",
       "      <td>3185.591714</td>\n",
       "      <td>0.920877</td>\n",
       "      <td>0.920786</td>\n",
       "      <td>1.064013</td>\n",
       "      <td>0.990855</td>\n",
       "      <td>534.140819</td>\n",
       "      <td>0.364438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362499</th>\n",
       "      <td>0.749872</td>\n",
       "      <td>0.800834</td>\n",
       "      <td>0.842750</td>\n",
       "      <td>0.719020</td>\n",
       "      <td>0.287853</td>\n",
       "      <td>0.608888</td>\n",
       "      <td>0.437803</td>\n",
       "      <td>55.826486</td>\n",
       "      <td>452.874619</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>0.818049</td>\n",
       "      <td>0.561701</td>\n",
       "      <td>707.939208</td>\n",
       "      <td>3185.726437</td>\n",
       "      <td>0.562559</td>\n",
       "      <td>0.561892</td>\n",
       "      <td>1.690357</td>\n",
       "      <td>1.419079</td>\n",
       "      <td>387.264753</td>\n",
       "      <td>0.564494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362500</th>\n",
       "      <td>0.538644</td>\n",
       "      <td>0.788402</td>\n",
       "      <td>0.827843</td>\n",
       "      <td>0.727779</td>\n",
       "      <td>0.618701</td>\n",
       "      <td>0.694040</td>\n",
       "      <td>0.505108</td>\n",
       "      <td>6.365350</td>\n",
       "      <td>423.130196</td>\n",
       "      <td>0.050525</td>\n",
       "      <td>0.896188</td>\n",
       "      <td>0.993835</td>\n",
       "      <td>707.935903</td>\n",
       "      <td>3185.711565</td>\n",
       "      <td>0.993844</td>\n",
       "      <td>0.993837</td>\n",
       "      <td>0.959983</td>\n",
       "      <td>0.814335</td>\n",
       "      <td>476.450471</td>\n",
       "      <td>0.591383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362501</th>\n",
       "      <td>0.634018</td>\n",
       "      <td>0.991370</td>\n",
       "      <td>0.965507</td>\n",
       "      <td>0.661306</td>\n",
       "      <td>0.455678</td>\n",
       "      <td>0.103640</td>\n",
       "      <td>0.068538</td>\n",
       "      <td>7.738936</td>\n",
       "      <td>2006.981168</td>\n",
       "      <td>0.832208</td>\n",
       "      <td>0.860886</td>\n",
       "      <td>0.990892</td>\n",
       "      <td>708.111887</td>\n",
       "      <td>3186.503491</td>\n",
       "      <td>0.990905</td>\n",
       "      <td>0.990895</td>\n",
       "      <td>0.807461</td>\n",
       "      <td>0.369966</td>\n",
       "      <td>1015.811664</td>\n",
       "      <td>-0.093105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362502</th>\n",
       "      <td>0.323002</td>\n",
       "      <td>0.940875</td>\n",
       "      <td>0.665318</td>\n",
       "      <td>0.306548</td>\n",
       "      <td>1.130098</td>\n",
       "      <td>0.587625</td>\n",
       "      <td>0.180135</td>\n",
       "      <td>21.099784</td>\n",
       "      <td>354.152329</td>\n",
       "      <td>0.982156</td>\n",
       "      <td>0.832794</td>\n",
       "      <td>0.932955</td>\n",
       "      <td>707.928239</td>\n",
       "      <td>3185.677076</td>\n",
       "      <td>0.933053</td>\n",
       "      <td>0.932977</td>\n",
       "      <td>1.030396</td>\n",
       "      <td>0.897896</td>\n",
       "      <td>416.207341</td>\n",
       "      <td>0.463743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362503 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tg_scat    Tg_abs    Ta_abs       SSA       GOD       AOD      AODS  \\\n",
       "0       0.984234  0.967931  0.849827  0.595673  0.015892  0.402452  0.239730   \n",
       "1       0.808703  0.502863  0.971936  0.754977  0.212324  0.116173  0.087708   \n",
       "2       0.266592  0.973465  0.845395  0.580608  1.322036  0.400463  0.232512   \n",
       "3       0.830782  0.963485  0.971736  0.270474  0.185388  0.039302  0.010630   \n",
       "4       0.600291  0.839312  0.797427  0.652968  0.510340  0.652287  0.425923   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "362498  0.765135  0.641704  0.963197  0.825442  0.267702  0.214810  0.177313   \n",
       "362499  0.749872  0.800834  0.842750  0.719020  0.287853  0.608888  0.437803   \n",
       "362500  0.538644  0.788402  0.827843  0.727779  0.618701  0.694040  0.505108   \n",
       "362501  0.634018  0.991370  0.965507  0.661306  0.455678  0.103640  0.068538   \n",
       "362502  0.323002  0.940875  0.665318  0.306548  1.130098  0.587625  0.180135   \n",
       "\n",
       "              SZA            Z  R_scence        g1  Cos(SZA)        mu_g  \\\n",
       "0       81.357114  1137.064781  0.370253  0.946187  0.150275  708.015229   \n",
       "1       69.669734  2695.217813  0.364243  0.910936  0.347431  708.188358   \n",
       "2       17.550390  1081.897319  0.672173  0.896924  0.953452  708.009100   \n",
       "3       44.256621    81.149965  0.775990  0.869940  0.716221  707.897906   \n",
       "4       24.480144   932.892398  0.777209  0.878946  0.910105  707.992544   \n",
       "...           ...          ...       ...       ...       ...         ...   \n",
       "362498  22.962506   183.428535  0.740243  0.668902  0.920760  707.909270   \n",
       "362499  55.826486   452.874619  0.016449  0.818049  0.561701  707.939208   \n",
       "362500   6.365350   423.130196  0.050525  0.896188  0.993835  707.935903   \n",
       "362501   7.738936  2006.981168  0.832208  0.860886  0.990892  708.111887   \n",
       "362502  21.099784   354.152329  0.982156  0.832794  0.932955  707.928239   \n",
       "\n",
       "               mu_a  muprime_g  muprime_a  mprime_g  mprime_a       BOA_RT  \\\n",
       "0       3186.068532   0.154730   0.151289  5.695816  3.743539   429.332315   \n",
       "1       3186.847609   0.349206   0.347828  2.122562  0.747097   194.210750   \n",
       "2       3186.040949   0.953519   0.953467  0.929959  0.610609   648.404343   \n",
       "3       3185.540575   0.716701   0.716328  1.382759  1.340499   885.138727   \n",
       "4       3185.966446   0.910238   0.910135  0.990440  0.689159   602.697524   \n",
       "...             ...        ...        ...       ...       ...          ...   \n",
       "362498  3185.591714   0.920877   0.920786  1.064013  0.990855   534.140819   \n",
       "362499  3185.726437   0.562559   0.561892  1.690357  1.419079   387.264753   \n",
       "362500  3185.711565   0.993844   0.993837  0.959983  0.814335   476.450471   \n",
       "362501  3186.503491   0.990905   0.990895  0.807461  0.369966  1015.811664   \n",
       "362502  3185.677076   0.933053   0.932977  1.030396  0.897896   416.207341   \n",
       "\n",
       "           alpha  \n",
       "0       0.133511  \n",
       "1       0.363279  \n",
       "2       0.280041  \n",
       "3       0.125099  \n",
       "4       0.320636  \n",
       "...          ...  \n",
       "362498  0.364438  \n",
       "362499  0.564494  \n",
       "362500  0.591383  \n",
       "362501 -0.093105  \n",
       "362502  0.463743  \n",
       "\n",
       "[362503 rows x 20 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('no_outliers.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tg_scat</th>\n",
       "      <th>Tg_abs</th>\n",
       "      <th>Ta_abs</th>\n",
       "      <th>SSA</th>\n",
       "      <th>GOD</th>\n",
       "      <th>AOD</th>\n",
       "      <th>AODS</th>\n",
       "      <th>SZA</th>\n",
       "      <th>Z</th>\n",
       "      <th>R_scence</th>\n",
       "      <th>...</th>\n",
       "      <th>Cos(SZA)</th>\n",
       "      <th>mu_g</th>\n",
       "      <th>mu_a</th>\n",
       "      <th>muprime_g</th>\n",
       "      <th>muprime_a</th>\n",
       "      <th>mprime_g</th>\n",
       "      <th>mprime_a</th>\n",
       "      <th>BOA_RT</th>\n",
       "      <th>alpha</th>\n",
       "      <th>BOA_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.984234</td>\n",
       "      <td>0.967931</td>\n",
       "      <td>0.849827</td>\n",
       "      <td>0.595673</td>\n",
       "      <td>0.015892</td>\n",
       "      <td>0.402452</td>\n",
       "      <td>0.239730</td>\n",
       "      <td>81.357114</td>\n",
       "      <td>1137.064781</td>\n",
       "      <td>0.370253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150275</td>\n",
       "      <td>708.015229</td>\n",
       "      <td>3186.068532</td>\n",
       "      <td>0.154730</td>\n",
       "      <td>0.151289</td>\n",
       "      <td>5.695816</td>\n",
       "      <td>3.743539</td>\n",
       "      <td>429.332315</td>\n",
       "      <td>0.133511</td>\n",
       "      <td>0.429332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.808703</td>\n",
       "      <td>0.502863</td>\n",
       "      <td>0.971936</td>\n",
       "      <td>0.754977</td>\n",
       "      <td>0.212324</td>\n",
       "      <td>0.116173</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>69.669734</td>\n",
       "      <td>2695.217813</td>\n",
       "      <td>0.364243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347431</td>\n",
       "      <td>708.188358</td>\n",
       "      <td>3186.847609</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.347828</td>\n",
       "      <td>2.122562</td>\n",
       "      <td>0.747097</td>\n",
       "      <td>194.210750</td>\n",
       "      <td>0.363279</td>\n",
       "      <td>0.194211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266592</td>\n",
       "      <td>0.973465</td>\n",
       "      <td>0.845395</td>\n",
       "      <td>0.580608</td>\n",
       "      <td>1.322036</td>\n",
       "      <td>0.400463</td>\n",
       "      <td>0.232512</td>\n",
       "      <td>17.550390</td>\n",
       "      <td>1081.897319</td>\n",
       "      <td>0.672173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953452</td>\n",
       "      <td>708.009100</td>\n",
       "      <td>3186.040949</td>\n",
       "      <td>0.953519</td>\n",
       "      <td>0.953467</td>\n",
       "      <td>0.929959</td>\n",
       "      <td>0.610609</td>\n",
       "      <td>648.404343</td>\n",
       "      <td>0.280041</td>\n",
       "      <td>0.648404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830782</td>\n",
       "      <td>0.963485</td>\n",
       "      <td>0.971736</td>\n",
       "      <td>0.270474</td>\n",
       "      <td>0.185388</td>\n",
       "      <td>0.039302</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>44.256621</td>\n",
       "      <td>81.149965</td>\n",
       "      <td>0.775990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716221</td>\n",
       "      <td>707.897906</td>\n",
       "      <td>3185.540575</td>\n",
       "      <td>0.716701</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>1.382759</td>\n",
       "      <td>1.340499</td>\n",
       "      <td>885.138727</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>0.885139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600291</td>\n",
       "      <td>0.839312</td>\n",
       "      <td>0.797427</td>\n",
       "      <td>0.652968</td>\n",
       "      <td>0.510340</td>\n",
       "      <td>0.652287</td>\n",
       "      <td>0.425923</td>\n",
       "      <td>24.480144</td>\n",
       "      <td>932.892398</td>\n",
       "      <td>0.777209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910105</td>\n",
       "      <td>707.992544</td>\n",
       "      <td>3185.966446</td>\n",
       "      <td>0.910238</td>\n",
       "      <td>0.910135</td>\n",
       "      <td>0.990440</td>\n",
       "      <td>0.689159</td>\n",
       "      <td>602.697524</td>\n",
       "      <td>0.320636</td>\n",
       "      <td>0.602698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362498</th>\n",
       "      <td>0.765135</td>\n",
       "      <td>0.641704</td>\n",
       "      <td>0.963197</td>\n",
       "      <td>0.825442</td>\n",
       "      <td>0.267702</td>\n",
       "      <td>0.214810</td>\n",
       "      <td>0.177313</td>\n",
       "      <td>22.962506</td>\n",
       "      <td>183.428535</td>\n",
       "      <td>0.740243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920760</td>\n",
       "      <td>707.909270</td>\n",
       "      <td>3185.591714</td>\n",
       "      <td>0.920877</td>\n",
       "      <td>0.920786</td>\n",
       "      <td>1.064013</td>\n",
       "      <td>0.990855</td>\n",
       "      <td>534.140819</td>\n",
       "      <td>0.364438</td>\n",
       "      <td>0.534141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362499</th>\n",
       "      <td>0.749872</td>\n",
       "      <td>0.800834</td>\n",
       "      <td>0.842750</td>\n",
       "      <td>0.719020</td>\n",
       "      <td>0.287853</td>\n",
       "      <td>0.608888</td>\n",
       "      <td>0.437803</td>\n",
       "      <td>55.826486</td>\n",
       "      <td>452.874619</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561701</td>\n",
       "      <td>707.939208</td>\n",
       "      <td>3185.726437</td>\n",
       "      <td>0.562559</td>\n",
       "      <td>0.561892</td>\n",
       "      <td>1.690357</td>\n",
       "      <td>1.419079</td>\n",
       "      <td>387.264753</td>\n",
       "      <td>0.564494</td>\n",
       "      <td>0.387265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362500</th>\n",
       "      <td>0.538644</td>\n",
       "      <td>0.788402</td>\n",
       "      <td>0.827843</td>\n",
       "      <td>0.727779</td>\n",
       "      <td>0.618701</td>\n",
       "      <td>0.694040</td>\n",
       "      <td>0.505108</td>\n",
       "      <td>6.365350</td>\n",
       "      <td>423.130196</td>\n",
       "      <td>0.050525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993835</td>\n",
       "      <td>707.935903</td>\n",
       "      <td>3185.711565</td>\n",
       "      <td>0.993844</td>\n",
       "      <td>0.993837</td>\n",
       "      <td>0.959983</td>\n",
       "      <td>0.814335</td>\n",
       "      <td>476.450471</td>\n",
       "      <td>0.591383</td>\n",
       "      <td>0.476450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362501</th>\n",
       "      <td>0.634018</td>\n",
       "      <td>0.991370</td>\n",
       "      <td>0.965507</td>\n",
       "      <td>0.661306</td>\n",
       "      <td>0.455678</td>\n",
       "      <td>0.103640</td>\n",
       "      <td>0.068538</td>\n",
       "      <td>7.738936</td>\n",
       "      <td>2006.981168</td>\n",
       "      <td>0.832208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990892</td>\n",
       "      <td>708.111887</td>\n",
       "      <td>3186.503491</td>\n",
       "      <td>0.990905</td>\n",
       "      <td>0.990895</td>\n",
       "      <td>0.807461</td>\n",
       "      <td>0.369966</td>\n",
       "      <td>1015.811664</td>\n",
       "      <td>-0.093105</td>\n",
       "      <td>1.015812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362502</th>\n",
       "      <td>0.323002</td>\n",
       "      <td>0.940875</td>\n",
       "      <td>0.665318</td>\n",
       "      <td>0.306548</td>\n",
       "      <td>1.130098</td>\n",
       "      <td>0.587625</td>\n",
       "      <td>0.180135</td>\n",
       "      <td>21.099784</td>\n",
       "      <td>354.152329</td>\n",
       "      <td>0.982156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932955</td>\n",
       "      <td>707.928239</td>\n",
       "      <td>3185.677076</td>\n",
       "      <td>0.933053</td>\n",
       "      <td>0.932977</td>\n",
       "      <td>1.030396</td>\n",
       "      <td>0.897896</td>\n",
       "      <td>416.207341</td>\n",
       "      <td>0.463743</td>\n",
       "      <td>0.416207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362503 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tg_scat    Tg_abs    Ta_abs       SSA       GOD       AOD      AODS  \\\n",
       "0       0.984234  0.967931  0.849827  0.595673  0.015892  0.402452  0.239730   \n",
       "1       0.808703  0.502863  0.971936  0.754977  0.212324  0.116173  0.087708   \n",
       "2       0.266592  0.973465  0.845395  0.580608  1.322036  0.400463  0.232512   \n",
       "3       0.830782  0.963485  0.971736  0.270474  0.185388  0.039302  0.010630   \n",
       "4       0.600291  0.839312  0.797427  0.652968  0.510340  0.652287  0.425923   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "362498  0.765135  0.641704  0.963197  0.825442  0.267702  0.214810  0.177313   \n",
       "362499  0.749872  0.800834  0.842750  0.719020  0.287853  0.608888  0.437803   \n",
       "362500  0.538644  0.788402  0.827843  0.727779  0.618701  0.694040  0.505108   \n",
       "362501  0.634018  0.991370  0.965507  0.661306  0.455678  0.103640  0.068538   \n",
       "362502  0.323002  0.940875  0.665318  0.306548  1.130098  0.587625  0.180135   \n",
       "\n",
       "              SZA            Z  R_scence  ...  Cos(SZA)        mu_g  \\\n",
       "0       81.357114  1137.064781  0.370253  ...  0.150275  708.015229   \n",
       "1       69.669734  2695.217813  0.364243  ...  0.347431  708.188358   \n",
       "2       17.550390  1081.897319  0.672173  ...  0.953452  708.009100   \n",
       "3       44.256621    81.149965  0.775990  ...  0.716221  707.897906   \n",
       "4       24.480144   932.892398  0.777209  ...  0.910105  707.992544   \n",
       "...           ...          ...       ...  ...       ...         ...   \n",
       "362498  22.962506   183.428535  0.740243  ...  0.920760  707.909270   \n",
       "362499  55.826486   452.874619  0.016449  ...  0.561701  707.939208   \n",
       "362500   6.365350   423.130196  0.050525  ...  0.993835  707.935903   \n",
       "362501   7.738936  2006.981168  0.832208  ...  0.990892  708.111887   \n",
       "362502  21.099784   354.152329  0.982156  ...  0.932955  707.928239   \n",
       "\n",
       "               mu_a  muprime_g  muprime_a  mprime_g  mprime_a       BOA_RT  \\\n",
       "0       3186.068532   0.154730   0.151289  5.695816  3.743539   429.332315   \n",
       "1       3186.847609   0.349206   0.347828  2.122562  0.747097   194.210750   \n",
       "2       3186.040949   0.953519   0.953467  0.929959  0.610609   648.404343   \n",
       "3       3185.540575   0.716701   0.716328  1.382759  1.340499   885.138727   \n",
       "4       3185.966446   0.910238   0.910135  0.990440  0.689159   602.697524   \n",
       "...             ...        ...        ...       ...       ...          ...   \n",
       "362498  3185.591714   0.920877   0.920786  1.064013  0.990855   534.140819   \n",
       "362499  3185.726437   0.562559   0.561892  1.690357  1.419079   387.264753   \n",
       "362500  3185.711565   0.993844   0.993837  0.959983  0.814335   476.450471   \n",
       "362501  3186.503491   0.990905   0.990895  0.807461  0.369966  1015.811664   \n",
       "362502  3185.677076   0.933053   0.932977  1.030396  0.897896   416.207341   \n",
       "\n",
       "           alpha  BOA_fraction  \n",
       "0       0.133511      0.429332  \n",
       "1       0.363279      0.194211  \n",
       "2       0.280041      0.648404  \n",
       "3       0.125099      0.885139  \n",
       "4       0.320636      0.602698  \n",
       "...          ...           ...  \n",
       "362498  0.364438      0.534141  \n",
       "362499  0.564494      0.387265  \n",
       "362500  0.591383      0.476450  \n",
       "362501 -0.093105      1.015812  \n",
       "362502  0.463743      0.416207  \n",
       "\n",
       "[362503 rows x 21 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['BOA_fraction']=data['BOA_RT']/1000\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOA_RT=data['BOA_RT']\n",
    "data.drop(columns=['BOA_RT'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tg_scat</th>\n",
       "      <th>Tg_abs</th>\n",
       "      <th>Ta_abs</th>\n",
       "      <th>SSA</th>\n",
       "      <th>GOD</th>\n",
       "      <th>AOD</th>\n",
       "      <th>AODS</th>\n",
       "      <th>SZA</th>\n",
       "      <th>Z</th>\n",
       "      <th>R_scence</th>\n",
       "      <th>g1</th>\n",
       "      <th>Cos(SZA)</th>\n",
       "      <th>mu_g</th>\n",
       "      <th>mu_a</th>\n",
       "      <th>muprime_g</th>\n",
       "      <th>muprime_a</th>\n",
       "      <th>mprime_g</th>\n",
       "      <th>mprime_a</th>\n",
       "      <th>BOA_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.984234</td>\n",
       "      <td>0.967931</td>\n",
       "      <td>0.849827</td>\n",
       "      <td>0.595673</td>\n",
       "      <td>0.015892</td>\n",
       "      <td>0.402452</td>\n",
       "      <td>0.239730</td>\n",
       "      <td>81.357114</td>\n",
       "      <td>1137.064781</td>\n",
       "      <td>0.370253</td>\n",
       "      <td>0.946187</td>\n",
       "      <td>0.150275</td>\n",
       "      <td>708.015229</td>\n",
       "      <td>3186.068532</td>\n",
       "      <td>0.154730</td>\n",
       "      <td>0.151289</td>\n",
       "      <td>5.695816</td>\n",
       "      <td>3.743539</td>\n",
       "      <td>0.429332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.808703</td>\n",
       "      <td>0.502863</td>\n",
       "      <td>0.971936</td>\n",
       "      <td>0.754977</td>\n",
       "      <td>0.212324</td>\n",
       "      <td>0.116173</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>69.669734</td>\n",
       "      <td>2695.217813</td>\n",
       "      <td>0.364243</td>\n",
       "      <td>0.910936</td>\n",
       "      <td>0.347431</td>\n",
       "      <td>708.188358</td>\n",
       "      <td>3186.847609</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.347828</td>\n",
       "      <td>2.122562</td>\n",
       "      <td>0.747097</td>\n",
       "      <td>0.194211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266592</td>\n",
       "      <td>0.973465</td>\n",
       "      <td>0.845395</td>\n",
       "      <td>0.580608</td>\n",
       "      <td>1.322036</td>\n",
       "      <td>0.400463</td>\n",
       "      <td>0.232512</td>\n",
       "      <td>17.550390</td>\n",
       "      <td>1081.897319</td>\n",
       "      <td>0.672173</td>\n",
       "      <td>0.896924</td>\n",
       "      <td>0.953452</td>\n",
       "      <td>708.009100</td>\n",
       "      <td>3186.040949</td>\n",
       "      <td>0.953519</td>\n",
       "      <td>0.953467</td>\n",
       "      <td>0.929959</td>\n",
       "      <td>0.610609</td>\n",
       "      <td>0.648404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830782</td>\n",
       "      <td>0.963485</td>\n",
       "      <td>0.971736</td>\n",
       "      <td>0.270474</td>\n",
       "      <td>0.185388</td>\n",
       "      <td>0.039302</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>44.256621</td>\n",
       "      <td>81.149965</td>\n",
       "      <td>0.775990</td>\n",
       "      <td>0.869940</td>\n",
       "      <td>0.716221</td>\n",
       "      <td>707.897906</td>\n",
       "      <td>3185.540575</td>\n",
       "      <td>0.716701</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>1.382759</td>\n",
       "      <td>1.340499</td>\n",
       "      <td>0.885139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600291</td>\n",
       "      <td>0.839312</td>\n",
       "      <td>0.797427</td>\n",
       "      <td>0.652968</td>\n",
       "      <td>0.510340</td>\n",
       "      <td>0.652287</td>\n",
       "      <td>0.425923</td>\n",
       "      <td>24.480144</td>\n",
       "      <td>932.892398</td>\n",
       "      <td>0.777209</td>\n",
       "      <td>0.878946</td>\n",
       "      <td>0.910105</td>\n",
       "      <td>707.992544</td>\n",
       "      <td>3185.966446</td>\n",
       "      <td>0.910238</td>\n",
       "      <td>0.910135</td>\n",
       "      <td>0.990440</td>\n",
       "      <td>0.689159</td>\n",
       "      <td>0.602698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362498</th>\n",
       "      <td>0.765135</td>\n",
       "      <td>0.641704</td>\n",
       "      <td>0.963197</td>\n",
       "      <td>0.825442</td>\n",
       "      <td>0.267702</td>\n",
       "      <td>0.214810</td>\n",
       "      <td>0.177313</td>\n",
       "      <td>22.962506</td>\n",
       "      <td>183.428535</td>\n",
       "      <td>0.740243</td>\n",
       "      <td>0.668902</td>\n",
       "      <td>0.920760</td>\n",
       "      <td>707.909270</td>\n",
       "      <td>3185.591714</td>\n",
       "      <td>0.920877</td>\n",
       "      <td>0.920786</td>\n",
       "      <td>1.064013</td>\n",
       "      <td>0.990855</td>\n",
       "      <td>0.534141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362499</th>\n",
       "      <td>0.749872</td>\n",
       "      <td>0.800834</td>\n",
       "      <td>0.842750</td>\n",
       "      <td>0.719020</td>\n",
       "      <td>0.287853</td>\n",
       "      <td>0.608888</td>\n",
       "      <td>0.437803</td>\n",
       "      <td>55.826486</td>\n",
       "      <td>452.874619</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>0.818049</td>\n",
       "      <td>0.561701</td>\n",
       "      <td>707.939208</td>\n",
       "      <td>3185.726437</td>\n",
       "      <td>0.562559</td>\n",
       "      <td>0.561892</td>\n",
       "      <td>1.690357</td>\n",
       "      <td>1.419079</td>\n",
       "      <td>0.387265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362500</th>\n",
       "      <td>0.538644</td>\n",
       "      <td>0.788402</td>\n",
       "      <td>0.827843</td>\n",
       "      <td>0.727779</td>\n",
       "      <td>0.618701</td>\n",
       "      <td>0.694040</td>\n",
       "      <td>0.505108</td>\n",
       "      <td>6.365350</td>\n",
       "      <td>423.130196</td>\n",
       "      <td>0.050525</td>\n",
       "      <td>0.896188</td>\n",
       "      <td>0.993835</td>\n",
       "      <td>707.935903</td>\n",
       "      <td>3185.711565</td>\n",
       "      <td>0.993844</td>\n",
       "      <td>0.993837</td>\n",
       "      <td>0.959983</td>\n",
       "      <td>0.814335</td>\n",
       "      <td>0.476450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362501</th>\n",
       "      <td>0.634018</td>\n",
       "      <td>0.991370</td>\n",
       "      <td>0.965507</td>\n",
       "      <td>0.661306</td>\n",
       "      <td>0.455678</td>\n",
       "      <td>0.103640</td>\n",
       "      <td>0.068538</td>\n",
       "      <td>7.738936</td>\n",
       "      <td>2006.981168</td>\n",
       "      <td>0.832208</td>\n",
       "      <td>0.860886</td>\n",
       "      <td>0.990892</td>\n",
       "      <td>708.111887</td>\n",
       "      <td>3186.503491</td>\n",
       "      <td>0.990905</td>\n",
       "      <td>0.990895</td>\n",
       "      <td>0.807461</td>\n",
       "      <td>0.369966</td>\n",
       "      <td>1.015812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362502</th>\n",
       "      <td>0.323002</td>\n",
       "      <td>0.940875</td>\n",
       "      <td>0.665318</td>\n",
       "      <td>0.306548</td>\n",
       "      <td>1.130098</td>\n",
       "      <td>0.587625</td>\n",
       "      <td>0.180135</td>\n",
       "      <td>21.099784</td>\n",
       "      <td>354.152329</td>\n",
       "      <td>0.982156</td>\n",
       "      <td>0.832794</td>\n",
       "      <td>0.932955</td>\n",
       "      <td>707.928239</td>\n",
       "      <td>3185.677076</td>\n",
       "      <td>0.933053</td>\n",
       "      <td>0.932977</td>\n",
       "      <td>1.030396</td>\n",
       "      <td>0.897896</td>\n",
       "      <td>0.416207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362503 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tg_scat    Tg_abs    Ta_abs       SSA       GOD       AOD      AODS  \\\n",
       "0       0.984234  0.967931  0.849827  0.595673  0.015892  0.402452  0.239730   \n",
       "1       0.808703  0.502863  0.971936  0.754977  0.212324  0.116173  0.087708   \n",
       "2       0.266592  0.973465  0.845395  0.580608  1.322036  0.400463  0.232512   \n",
       "3       0.830782  0.963485  0.971736  0.270474  0.185388  0.039302  0.010630   \n",
       "4       0.600291  0.839312  0.797427  0.652968  0.510340  0.652287  0.425923   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "362498  0.765135  0.641704  0.963197  0.825442  0.267702  0.214810  0.177313   \n",
       "362499  0.749872  0.800834  0.842750  0.719020  0.287853  0.608888  0.437803   \n",
       "362500  0.538644  0.788402  0.827843  0.727779  0.618701  0.694040  0.505108   \n",
       "362501  0.634018  0.991370  0.965507  0.661306  0.455678  0.103640  0.068538   \n",
       "362502  0.323002  0.940875  0.665318  0.306548  1.130098  0.587625  0.180135   \n",
       "\n",
       "              SZA            Z  R_scence        g1  Cos(SZA)        mu_g  \\\n",
       "0       81.357114  1137.064781  0.370253  0.946187  0.150275  708.015229   \n",
       "1       69.669734  2695.217813  0.364243  0.910936  0.347431  708.188358   \n",
       "2       17.550390  1081.897319  0.672173  0.896924  0.953452  708.009100   \n",
       "3       44.256621    81.149965  0.775990  0.869940  0.716221  707.897906   \n",
       "4       24.480144   932.892398  0.777209  0.878946  0.910105  707.992544   \n",
       "...           ...          ...       ...       ...       ...         ...   \n",
       "362498  22.962506   183.428535  0.740243  0.668902  0.920760  707.909270   \n",
       "362499  55.826486   452.874619  0.016449  0.818049  0.561701  707.939208   \n",
       "362500   6.365350   423.130196  0.050525  0.896188  0.993835  707.935903   \n",
       "362501   7.738936  2006.981168  0.832208  0.860886  0.990892  708.111887   \n",
       "362502  21.099784   354.152329  0.982156  0.832794  0.932955  707.928239   \n",
       "\n",
       "               mu_a  muprime_g  muprime_a  mprime_g  mprime_a  BOA_fraction  \n",
       "0       3186.068532   0.154730   0.151289  5.695816  3.743539      0.429332  \n",
       "1       3186.847609   0.349206   0.347828  2.122562  0.747097      0.194211  \n",
       "2       3186.040949   0.953519   0.953467  0.929959  0.610609      0.648404  \n",
       "3       3185.540575   0.716701   0.716328  1.382759  1.340499      0.885139  \n",
       "4       3185.966446   0.910238   0.910135  0.990440  0.689159      0.602698  \n",
       "...             ...        ...        ...       ...       ...           ...  \n",
       "362498  3185.591714   0.920877   0.920786  1.064013  0.990855      0.534141  \n",
       "362499  3185.726437   0.562559   0.561892  1.690357  1.419079      0.387265  \n",
       "362500  3185.711565   0.993844   0.993837  0.959983  0.814335      0.476450  \n",
       "362501  3186.503491   0.990905   0.990895  0.807461  0.369966      1.015812  \n",
       "362502  3185.677076   0.933053   0.932977  1.030396  0.897896      0.416207  \n",
       "\n",
       "[362503 rows x 19 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=['alpha'],inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler_y=StandardScaler()\n",
    "cols_to_scale = data.drop(columns=['BOA_fraction']).columns\n",
    "X_scaled = scaler.fit_transform(data[cols_to_scale])\n",
    "y_scaled=scaler_y.fit_transform(data['BOA_fraction'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y_scaled,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"best_params.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(Dense(params[\"units1\"], activation=params[\"activation\"], input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(params[\"dropout1\"]))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Dense(params[\"units2\"], activation=params[\"activation\"]))\n",
    "model.add(Dropout(params[\"dropout2\"]))\n",
    "\n",
    "# Layer 3 (if applicable)\n",
    "if params[\"n_layers\"] >= 3:\n",
    "    model.add(Dense(params[\"units3\"], activation=params[\"activation\"]))\n",
    "    model.add(Dropout(params[\"dropout3\"]))\n",
    "\n",
    "# Layer 4 (if applicable)\n",
    "if params[\"n_layers\"] == 4:\n",
    "    model.add(Dense(params[\"units4\"], activation=params[\"activation\"]))\n",
    "    model.add(Dropout(params[\"dropout4\"]))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=params[\"lr\"])\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class TransmissionLayer(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        alpha, m_g, m_a, dtau_gas_scat, dtau_aero_scat, T_gas_abs, T_aero_abs = inputs\n",
    "\n",
    "        # Dénominateur (1 + α⋅Δτ_gas⋅m_g + α/3⋅Δτ_aero⋅m_a)\n",
    "        denom = 1 + alpha * dtau_gas_scat * m_g + (alpha / 3.0) * dtau_aero_scat * m_a\n",
    "\n",
    "        # Absorptions\n",
    "        T_abs = tf.pow(T_gas_abs, m_g) * tf.pow(T_aero_abs, m_a)\n",
    "\n",
    "        # E_BOA / E_TOA\n",
    "        E_BOA_div_TOA = (T_abs/ denom) \n",
    "        return E_BOA_div_TOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Entrée principale : 18 descripteurs\n",
    "features_input = Input(shape=(18,), name='features')\n",
    "\n",
    "# Autres entrées nécessaires à la formule analytique\n",
    "m_g_input = Input(shape=(1,), name='mprime_g')\n",
    "m_a_input = Input(shape=(1,), name='mprime_a')\n",
    "dtau_gas_scat_input = Input(shape=(1,), name='GOD')\n",
    "dtau_aero_scat_input = Input(shape=(1,), name='AODS')\n",
    "T_gas_abs_input = Input(shape=(1,), name='Tg_abs')\n",
    "T_aero_abs_input = Input(shape=(1,), name='Ta_abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(232, activation='elu')(features_input)\n",
    "x = Dropout(0.111)(x)\n",
    "x = Dense(249, activation='elu')(x)\n",
    "x = Dropout(0.138)(x)\n",
    "x = Dense(174, activation='elu')(x)\n",
    "x = Dropout(0.136)(x)\n",
    "\n",
    "# Prédiction de alpha\n",
    "alpha_output = Dense(1, name='alpha')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_BOA_div_TOA = TransmissionLayer()([\n",
    "    alpha_output,\n",
    "    m_g_input,\n",
    "    m_a_input,\n",
    "    dtau_gas_scat_input,\n",
    "    dtau_aero_scat_input,\n",
    "    T_gas_abs_input,\n",
    "    T_aero_abs_input\n",
    "])\n",
    "model = Model(\n",
    "    inputs=[features_input, m_g_input, m_a_input, dtau_gas_scat_input, dtau_aero_scat_input, T_gas_abs_input, T_aero_abs_input],\n",
    "    outputs=E_BOA_div_TOA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00034),\n",
    "    loss='mae',  # ou 'mae' selon ce que tu veux\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tg_scat</th>\n",
       "      <th>Tg_abs</th>\n",
       "      <th>Ta_abs</th>\n",
       "      <th>SSA</th>\n",
       "      <th>GOD</th>\n",
       "      <th>AOD</th>\n",
       "      <th>AODS</th>\n",
       "      <th>SZA</th>\n",
       "      <th>Z</th>\n",
       "      <th>R_scence</th>\n",
       "      <th>g1</th>\n",
       "      <th>Cos(SZA)</th>\n",
       "      <th>mu_g</th>\n",
       "      <th>mu_a</th>\n",
       "      <th>muprime_g</th>\n",
       "      <th>muprime_a</th>\n",
       "      <th>mprime_g</th>\n",
       "      <th>mprime_a</th>\n",
       "      <th>BOA_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.984234</td>\n",
       "      <td>0.967931</td>\n",
       "      <td>0.849827</td>\n",
       "      <td>0.595673</td>\n",
       "      <td>0.015892</td>\n",
       "      <td>0.402452</td>\n",
       "      <td>0.239730</td>\n",
       "      <td>81.357114</td>\n",
       "      <td>1137.064781</td>\n",
       "      <td>0.370253</td>\n",
       "      <td>0.946187</td>\n",
       "      <td>0.150275</td>\n",
       "      <td>708.015229</td>\n",
       "      <td>3186.068532</td>\n",
       "      <td>0.154730</td>\n",
       "      <td>0.151289</td>\n",
       "      <td>5.695816</td>\n",
       "      <td>3.743539</td>\n",
       "      <td>0.429332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.808703</td>\n",
       "      <td>0.502863</td>\n",
       "      <td>0.971936</td>\n",
       "      <td>0.754977</td>\n",
       "      <td>0.212324</td>\n",
       "      <td>0.116173</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>69.669734</td>\n",
       "      <td>2695.217813</td>\n",
       "      <td>0.364243</td>\n",
       "      <td>0.910936</td>\n",
       "      <td>0.347431</td>\n",
       "      <td>708.188358</td>\n",
       "      <td>3186.847609</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.347828</td>\n",
       "      <td>2.122562</td>\n",
       "      <td>0.747097</td>\n",
       "      <td>0.194211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266592</td>\n",
       "      <td>0.973465</td>\n",
       "      <td>0.845395</td>\n",
       "      <td>0.580608</td>\n",
       "      <td>1.322036</td>\n",
       "      <td>0.400463</td>\n",
       "      <td>0.232512</td>\n",
       "      <td>17.550390</td>\n",
       "      <td>1081.897319</td>\n",
       "      <td>0.672173</td>\n",
       "      <td>0.896924</td>\n",
       "      <td>0.953452</td>\n",
       "      <td>708.009100</td>\n",
       "      <td>3186.040949</td>\n",
       "      <td>0.953519</td>\n",
       "      <td>0.953467</td>\n",
       "      <td>0.929959</td>\n",
       "      <td>0.610609</td>\n",
       "      <td>0.648404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830782</td>\n",
       "      <td>0.963485</td>\n",
       "      <td>0.971736</td>\n",
       "      <td>0.270474</td>\n",
       "      <td>0.185388</td>\n",
       "      <td>0.039302</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>44.256621</td>\n",
       "      <td>81.149965</td>\n",
       "      <td>0.775990</td>\n",
       "      <td>0.869940</td>\n",
       "      <td>0.716221</td>\n",
       "      <td>707.897906</td>\n",
       "      <td>3185.540575</td>\n",
       "      <td>0.716701</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>1.382759</td>\n",
       "      <td>1.340499</td>\n",
       "      <td>0.885139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600291</td>\n",
       "      <td>0.839312</td>\n",
       "      <td>0.797427</td>\n",
       "      <td>0.652968</td>\n",
       "      <td>0.510340</td>\n",
       "      <td>0.652287</td>\n",
       "      <td>0.425923</td>\n",
       "      <td>24.480144</td>\n",
       "      <td>932.892398</td>\n",
       "      <td>0.777209</td>\n",
       "      <td>0.878946</td>\n",
       "      <td>0.910105</td>\n",
       "      <td>707.992544</td>\n",
       "      <td>3185.966446</td>\n",
       "      <td>0.910238</td>\n",
       "      <td>0.910135</td>\n",
       "      <td>0.990440</td>\n",
       "      <td>0.689159</td>\n",
       "      <td>0.602698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362498</th>\n",
       "      <td>0.765135</td>\n",
       "      <td>0.641704</td>\n",
       "      <td>0.963197</td>\n",
       "      <td>0.825442</td>\n",
       "      <td>0.267702</td>\n",
       "      <td>0.214810</td>\n",
       "      <td>0.177313</td>\n",
       "      <td>22.962506</td>\n",
       "      <td>183.428535</td>\n",
       "      <td>0.740243</td>\n",
       "      <td>0.668902</td>\n",
       "      <td>0.920760</td>\n",
       "      <td>707.909270</td>\n",
       "      <td>3185.591714</td>\n",
       "      <td>0.920877</td>\n",
       "      <td>0.920786</td>\n",
       "      <td>1.064013</td>\n",
       "      <td>0.990855</td>\n",
       "      <td>0.534141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362499</th>\n",
       "      <td>0.749872</td>\n",
       "      <td>0.800834</td>\n",
       "      <td>0.842750</td>\n",
       "      <td>0.719020</td>\n",
       "      <td>0.287853</td>\n",
       "      <td>0.608888</td>\n",
       "      <td>0.437803</td>\n",
       "      <td>55.826486</td>\n",
       "      <td>452.874619</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>0.818049</td>\n",
       "      <td>0.561701</td>\n",
       "      <td>707.939208</td>\n",
       "      <td>3185.726437</td>\n",
       "      <td>0.562559</td>\n",
       "      <td>0.561892</td>\n",
       "      <td>1.690357</td>\n",
       "      <td>1.419079</td>\n",
       "      <td>0.387265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362500</th>\n",
       "      <td>0.538644</td>\n",
       "      <td>0.788402</td>\n",
       "      <td>0.827843</td>\n",
       "      <td>0.727779</td>\n",
       "      <td>0.618701</td>\n",
       "      <td>0.694040</td>\n",
       "      <td>0.505108</td>\n",
       "      <td>6.365350</td>\n",
       "      <td>423.130196</td>\n",
       "      <td>0.050525</td>\n",
       "      <td>0.896188</td>\n",
       "      <td>0.993835</td>\n",
       "      <td>707.935903</td>\n",
       "      <td>3185.711565</td>\n",
       "      <td>0.993844</td>\n",
       "      <td>0.993837</td>\n",
       "      <td>0.959983</td>\n",
       "      <td>0.814335</td>\n",
       "      <td>0.476450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362501</th>\n",
       "      <td>0.634018</td>\n",
       "      <td>0.991370</td>\n",
       "      <td>0.965507</td>\n",
       "      <td>0.661306</td>\n",
       "      <td>0.455678</td>\n",
       "      <td>0.103640</td>\n",
       "      <td>0.068538</td>\n",
       "      <td>7.738936</td>\n",
       "      <td>2006.981168</td>\n",
       "      <td>0.832208</td>\n",
       "      <td>0.860886</td>\n",
       "      <td>0.990892</td>\n",
       "      <td>708.111887</td>\n",
       "      <td>3186.503491</td>\n",
       "      <td>0.990905</td>\n",
       "      <td>0.990895</td>\n",
       "      <td>0.807461</td>\n",
       "      <td>0.369966</td>\n",
       "      <td>1.015812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362502</th>\n",
       "      <td>0.323002</td>\n",
       "      <td>0.940875</td>\n",
       "      <td>0.665318</td>\n",
       "      <td>0.306548</td>\n",
       "      <td>1.130098</td>\n",
       "      <td>0.587625</td>\n",
       "      <td>0.180135</td>\n",
       "      <td>21.099784</td>\n",
       "      <td>354.152329</td>\n",
       "      <td>0.982156</td>\n",
       "      <td>0.832794</td>\n",
       "      <td>0.932955</td>\n",
       "      <td>707.928239</td>\n",
       "      <td>3185.677076</td>\n",
       "      <td>0.933053</td>\n",
       "      <td>0.932977</td>\n",
       "      <td>1.030396</td>\n",
       "      <td>0.897896</td>\n",
       "      <td>0.416207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362503 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tg_scat    Tg_abs    Ta_abs       SSA       GOD       AOD      AODS  \\\n",
       "0       0.984234  0.967931  0.849827  0.595673  0.015892  0.402452  0.239730   \n",
       "1       0.808703  0.502863  0.971936  0.754977  0.212324  0.116173  0.087708   \n",
       "2       0.266592  0.973465  0.845395  0.580608  1.322036  0.400463  0.232512   \n",
       "3       0.830782  0.963485  0.971736  0.270474  0.185388  0.039302  0.010630   \n",
       "4       0.600291  0.839312  0.797427  0.652968  0.510340  0.652287  0.425923   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "362498  0.765135  0.641704  0.963197  0.825442  0.267702  0.214810  0.177313   \n",
       "362499  0.749872  0.800834  0.842750  0.719020  0.287853  0.608888  0.437803   \n",
       "362500  0.538644  0.788402  0.827843  0.727779  0.618701  0.694040  0.505108   \n",
       "362501  0.634018  0.991370  0.965507  0.661306  0.455678  0.103640  0.068538   \n",
       "362502  0.323002  0.940875  0.665318  0.306548  1.130098  0.587625  0.180135   \n",
       "\n",
       "              SZA            Z  R_scence        g1  Cos(SZA)        mu_g  \\\n",
       "0       81.357114  1137.064781  0.370253  0.946187  0.150275  708.015229   \n",
       "1       69.669734  2695.217813  0.364243  0.910936  0.347431  708.188358   \n",
       "2       17.550390  1081.897319  0.672173  0.896924  0.953452  708.009100   \n",
       "3       44.256621    81.149965  0.775990  0.869940  0.716221  707.897906   \n",
       "4       24.480144   932.892398  0.777209  0.878946  0.910105  707.992544   \n",
       "...           ...          ...       ...       ...       ...         ...   \n",
       "362498  22.962506   183.428535  0.740243  0.668902  0.920760  707.909270   \n",
       "362499  55.826486   452.874619  0.016449  0.818049  0.561701  707.939208   \n",
       "362500   6.365350   423.130196  0.050525  0.896188  0.993835  707.935903   \n",
       "362501   7.738936  2006.981168  0.832208  0.860886  0.990892  708.111887   \n",
       "362502  21.099784   354.152329  0.982156  0.832794  0.932955  707.928239   \n",
       "\n",
       "               mu_a  muprime_g  muprime_a  mprime_g  mprime_a  BOA_fraction  \n",
       "0       3186.068532   0.154730   0.151289  5.695816  3.743539      0.429332  \n",
       "1       3186.847609   0.349206   0.347828  2.122562  0.747097      0.194211  \n",
       "2       3186.040949   0.953519   0.953467  0.929959  0.610609      0.648404  \n",
       "3       3185.540575   0.716701   0.716328  1.382759  1.340499      0.885139  \n",
       "4       3185.966446   0.910238   0.910135  0.990440  0.689159      0.602698  \n",
       "...             ...        ...        ...       ...       ...           ...  \n",
       "362498  3185.591714   0.920877   0.920786  1.064013  0.990855      0.534141  \n",
       "362499  3185.726437   0.562559   0.561892  1.690357  1.419079      0.387265  \n",
       "362500  3185.711565   0.993844   0.993837  0.959983  0.814335      0.476450  \n",
       "362501  3186.503491   0.990905   0.990895  0.807461  0.369966      1.015812  \n",
       "362502  3185.677076   0.933053   0.932977  1.030396  0.897896      0.416207  \n",
       "\n",
       "[362503 rows x 19 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = data.iloc[:, :18].values\n",
    "\n",
    "# autres colonnes utilisées dans la couche analytique\n",
    "X_inputs = {\n",
    "    'features': X_features,\n",
    "    'mprime_g': data['mprime_g'].values.reshape(-1, 1),\n",
    "    'mprime_a': data['mprime_a'].values.reshape(-1, 1),\n",
    "    'GOD': data['GOD'].values.reshape(-1, 1),\n",
    "    'AODS': data['AODS'].values.reshape(-1, 1),\n",
    "    'Tg_abs': data['Tg_abs'].values.reshape(-1, 1),\n",
    "    'Ta_abs': data['Ta_abs'].values.reshape(-1, 1),\n",
    "}\n",
    "\n",
    "# y = valeur cible (E_BOA / E_TOA) → entre 0 et 1\n",
    "y = data['BOA_fraction'].values\n",
    "\n",
    "# entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 2. Reduce learning rate on plateau\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_mae',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3. Model checkpoint (save best model)\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath='deep_model_1.keras',\n",
    "    monitor='val_mae',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4. CSV logger (log training history)\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "csv_logger = CSVLogger(f'training_log_{timestamp}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4524/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5624 - mae: 0.5624\n",
      "Epoch 1: val_mae improved from inf to 0.55872, saving model to deep_model_1.keras\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - loss: 0.5624 - mae: 0.5624 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 3.4000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m4523/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5572 - mae: 0.5572\n",
      "Epoch 2: val_mae improved from 0.55872 to 0.55869, saving model to deep_model_1.keras\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 0.5572 - mae: 0.5572 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 3.4000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m4521/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5579 - mae: 0.5579\n",
      "Epoch 3: val_mae improved from 0.55869 to 0.55869, saving model to deep_model_1.keras\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 0.5579 - mae: 0.5579 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 3.4000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m4525/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5572 - mae: 0.5572\n",
      "Epoch 4: val_mae improved from 0.55869 to 0.55868, saving model to deep_model_1.keras\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 0.5572 - mae: 0.5572 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 3.4000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m4527/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5584 - mae: 0.5584\n",
      "Epoch 5: val_mae improved from 0.55868 to 0.55868, saving model to deep_model_1.keras\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 0.5584 - mae: 0.5584 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 3.4000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m4531/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5585 - mae: 0.5585\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00016999999934341758.\n",
      "\n",
      "Epoch 6: val_mae improved from 0.55868 to 0.55868, saving model to deep_model_1.keras\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 0.5585 - mae: 0.5585 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 3.4000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m4523/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5596 - mae: 0.5596\n",
      "Epoch 7: val_mae improved from 0.55868 to 0.55868, saving model to deep_model_1.keras\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 0.5596 - mae: 0.5596 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 1.7000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m4529/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5582 - mae: 0.5582\n",
      "Epoch 8: val_mae improved from 0.55868 to 0.55868, saving model to deep_model_1.keras\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - loss: 0.5582 - mae: 0.5582 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 1.7000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m4526/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5582 - mae: 0.5582\n",
      "Epoch 9: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - loss: 0.5582 - mae: 0.5582 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 1.7000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m4530/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5582 - mae: 0.5582\n",
      "Epoch 10: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 0.5582 - mae: 0.5582 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 1.7000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m4528/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5574 - mae: 0.5574\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 8.499999967170879e-05.\n",
      "\n",
      "Epoch 11: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 0.5575 - mae: 0.5575 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 1.7000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m4527/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5578 - mae: 0.5578\n",
      "Epoch 12: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 0.5578 - mae: 0.5578 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 8.5000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m4526/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5582 - mae: 0.5582\n",
      "Epoch 13: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - loss: 0.5582 - mae: 0.5582 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 8.5000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m4527/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5575 - mae: 0.5575\n",
      "Epoch 14: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - loss: 0.5575 - mae: 0.5575 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 8.5000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5576 - mae: 0.5576\n",
      "Epoch 15: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - loss: 0.5576 - mae: 0.5576 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 8.5000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m4524/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5574 - mae: 0.5574\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.2499999835854396e-05.\n",
      "\n",
      "Epoch 16: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 0.5574 - mae: 0.5574 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 8.5000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m4526/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5580 - mae: 0.5580\n",
      "Epoch 17: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - loss: 0.5580 - mae: 0.5580 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 4.2500e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m4527/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5574 - mae: 0.5574\n",
      "Epoch 18: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - loss: 0.5574 - mae: 0.5574 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 4.2500e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m4527/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5582 - mae: 0.5582\n",
      "Epoch 19: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - loss: 0.5582 - mae: 0.5582 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 4.2500e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m4531/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5580 - mae: 0.5580\n",
      "Epoch 20: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - loss: 0.5580 - mae: 0.5580 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 4.2500e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m4526/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5580 - mae: 0.5580\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.1249999917927198e-05.\n",
      "\n",
      "Epoch 21: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 0.5580 - mae: 0.5580 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 4.2500e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m4526/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5585 - mae: 0.5585\n",
      "Epoch 22: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - loss: 0.5585 - mae: 0.5585 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 2.1250e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m4529/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5571 - mae: 0.5571\n",
      "Epoch 23: val_mae did not improve from 0.55868\n",
      "\u001b[1m4532/4532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - loss: 0.5571 - mae: 0.5571 - val_loss: 0.5587 - val_mae: 0.5587 - learning_rate: 2.1250e-05\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7bd752273710>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_inputs,\n",
    "    y,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint_cb, csv_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_27\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_27\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_31      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">232</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,408</span> │ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_30          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">232</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">249</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">58,017</span> │ dropout_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">249</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">174</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,500</span> │ dropout_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">174</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">174</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_32      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_33      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_34      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_35      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_36      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_37      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ input_layer_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ input_layer_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ input_layer_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ input_layer_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ input_layer_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ input_layer_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_31      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m232\u001b[0m)       │      \u001b[38;5;34m4,408\u001b[0m │ input_layer_31[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_30          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m232\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m249\u001b[0m)       │     \u001b[38;5;34m58,017\u001b[0m │ dropout_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m249\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m174\u001b[0m)       │     \u001b[38;5;34m43,500\u001b[0m │ dropout_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m174\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_9 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m174\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_32      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_33      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_34      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_35      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_36      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_37      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_10 (\u001b[38;5;33mLambda\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lambda_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ input_layer_32[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ input_layer_33[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ input_layer_34[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ input_layer_35[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ input_layer_36[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ input_layer_37[\u001b[38;5;34m0\u001b[0m… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,925</span> (413.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m105,925\u001b[0m (413.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,925</span> (413.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,925\u001b[0m (413.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Lambda\n",
    "\n",
    "# Chargement des paramètres optimaux\n",
    "with open(\"best_params.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "# Fonction d'activation personnalisée qui ne reçoit les 6 paramètres qu'en sortie\n",
    "def transmission_activation(inputs):\n",
    "    alpha, m_g, m_a, dtau_gas_scat, dtau_aero_scat, T_gas_abs, T_aero_abs = inputs  # Décomposer la liste d'inputs\n",
    "    \n",
    "    # Dénominateur\n",
    "    denom = 1 + alpha * dtau_gas_scat * m_g + (alpha / 3.0) * dtau_aero_scat * m_a\n",
    "    \n",
    "    # Absorption\n",
    "    T_abs = tf.pow(T_gas_abs, m_g) * tf.pow(T_aero_abs, m_a)\n",
    "    \n",
    "    # Transmission finale\n",
    "    return T_abs / denom\n",
    "\n",
    "# Définition des entrées complètes\n",
    "input_features = Input(shape=(X_train.shape[1],))  # Inclut toutes les colonnes pour l'entraînement\n",
    "\n",
    "# Couches cachées\n",
    "hidden = Dense(params[\"units1\"], activation=params[\"activation\"])(input_features)\n",
    "hidden = Dropout(params[\"dropout1\"])(hidden)\n",
    "\n",
    "hidden = Dense(params[\"units2\"], activation=params[\"activation\"])(hidden)\n",
    "hidden = Dropout(params[\"dropout2\"])(hidden)\n",
    "\n",
    "if params[\"n_layers\"] >= 3:\n",
    "    hidden = Dense(params[\"units3\"], activation=params[\"activation\"])(hidden)\n",
    "    hidden = Dropout(params[\"dropout3\"])(hidden)\n",
    "\n",
    "if params[\"n_layers\"] == 4:\n",
    "    hidden = Dense(params[\"units4\"], activation=params[\"activation\"])(hidden)\n",
    "    hidden = Dropout(params[\"dropout4\"])(hidden)\n",
    "\n",
    "# Transmission directe de la sortie avant activation\n",
    "alpha = Lambda(lambda x: x)(hidden)  # Passage direct sans transformation\n",
    "\n",
    "# Entrées des 6 paramètres après entraînement\n",
    "input_m_g = Input(shape=(1,))\n",
    "input_m_a = Input(shape=(1,))\n",
    "input_dtau_gas_scat = Input(shape=(1,))\n",
    "input_dtau_aero_scat = Input(shape=(1,))\n",
    "input_T_gas_abs = Input(shape=(1,))\n",
    "input_T_aero_abs = Input(shape=(1,))\n",
    "\n",
    "# Application de la fonction analytique sur la sortie après entraînement\n",
    "# Application de la fonction analytique sur la sortie\n",
    "output = Lambda(lambda inputs: transmission_activation(inputs), output_shape=(None, 1))(\n",
    "    [alpha, input_m_g, input_m_a, input_dtau_gas_scat, input_dtau_aero_scat, input_T_gas_abs, input_T_aero_abs]\n",
    ")\n",
    "\n",
    "# Définition du modèle final\n",
    "model = Model(inputs=[input_features, input_m_g, input_m_a, input_dtau_gas_scat, input_dtau_aero_scat, input_T_gas_abs, input_T_aero_abs], outputs=output)\n",
    "\n",
    "# Compilation du modèle\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=params[\"lr\"])\n",
    "model.compile(optimizer=optimizer, loss='mae', metrics=['mae'])\n",
    "\n",
    "# Affichage du résumé du modèle\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362503,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "X_train=data.drop(columns=['BOA_fraction'])\n",
    "y_train=data['BOA_fraction']\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m_g = X_train[\"mprime_g\"].values.reshape(-1, 1)\n",
    "X_train_m_a = X_train[\"mprime_a\"].values.reshape(-1, 1)\n",
    "X_train_dtau_gas_scat = X_train[\"GOD\"].values.reshape(-1, 1)\n",
    "X_train_dtau_aero_scat = X_train[\"AODS\"].values.reshape(-1, 1)\n",
    "X_train_T_gas_abs = X_train[\"Tg_abs\"].values.reshape(-1, 1)\n",
    "X_train_T_aero_abs = X_train[\"Ta_abs\"].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m11329/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - loss: 1.5567 - mae: 1.5567\n",
      "Epoch 2/100\n",
      "\u001b[1m11329/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - loss: 1.6487 - mae: 1.6487\n",
      "Epoch 3/100\n",
      "\u001b[1m11329/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - loss: 1.7287 - mae: 1.7287\n",
      "Epoch 4/100\n",
      "\u001b[1m11329/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4ms/step - loss: 1.9605 - mae: 1.9605\n",
      "Epoch 5/100\n",
      "\u001b[1m11329/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - loss: 2.0148 - mae: 2.0148\n",
      "Epoch 6/100\n",
      "\u001b[1m11329/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4ms/step - loss: 2.1538 - mae: 2.1538\n",
      "Epoch 7/100\n",
      "\u001b[1m11329/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4ms/step - loss: 2.0942 - mae: 2.0942\n",
      "Epoch 8/100\n",
      "\u001b[1m11329/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - loss: 2.1925 - mae: 2.1925\n",
      "Epoch 9/100\n",
      "\u001b[1m11329/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4ms/step - loss: 2.1599 - mae: 2.1599\n",
      "Epoch 10/100\n",
      "\u001b[1m11329/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4ms/step - loss: 2.3423 - mae: 2.3423\n",
      "Epoch 11/100\n",
      "\u001b[1m11329/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4ms/step - loss: 2.1829 - mae: 2.1829\n",
      "Epoch 12/100\n",
      "\u001b[1m11329/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5ms/step - loss: 2.5867 - mae: 2.5867\n",
      "Epoch 13/100\n",
      "\u001b[1m11045/11329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.8319 - mae: 2.8319"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_m_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_m_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_dtau_gas_scat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_dtau_aero_scat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_T_gas_abs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_T_aero_abs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m    216\u001b[39m flat_outputs = \u001b[38;5;28mself\u001b[39m.call_flat(*args)\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpack_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:450\u001b[39m, in \u001b[36mFunctionType.pack_output\u001b[39m\u001b[34m(self, flat_values)\u001b[39m\n\u001b[32m    448\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not pack outputs for undefined output type.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mflat_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/tensorflow/python/framework/type_spec.py:264\u001b[39m, in \u001b[36mTypeSpec.from_tensors\u001b[39m\u001b[34m(self, tensors)\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"See TraceType base class for details. Do not override.\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m components = nest.map_structure(\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m spec: spec.from_tensors(tensors),\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m._component_specs\n\u001b[32m    263\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_from_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/tensorflow/python/data/ops/optional_ops.py:251\u001b[39m, in \u001b[36mOptionalSpec._from_components\u001b[39m\u001b[34m(self, flat_value)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_components\u001b[39m(\u001b[38;5;28mself\u001b[39m, flat_value):\n\u001b[32m    250\u001b[39m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_OptionalImpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_value\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_element_spec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/myptd/lib/python3.11/site-packages/tensorflow/python/data/ops/optional_ops.py:170\u001b[39m, in \u001b[36m_OptionalImpl.__init__\u001b[39m\u001b[34m(self, variant_tensor, element_spec)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, variant_tensor, element_spec):\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m   \u001b[38;5;28mself\u001b[39m._variant_tensor = variant_tensor\n\u001b[32m    172\u001b[39m   \u001b[38;5;28mself\u001b[39m._element_spec = element_spec\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train, X_train_m_g, X_train_m_a, X_train_dtau_gas_scat, X_train_dtau_aero_scat, X_train_T_gas_abs, X_train_T_aero_abs], \n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myptd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
